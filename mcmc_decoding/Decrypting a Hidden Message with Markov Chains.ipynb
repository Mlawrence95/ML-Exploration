{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> A Markov matrix (or stochastic matrix) </h1>\n",
    "\n",
    "<p> Gives the probability of reaching a set of states given a set of starting states. Here's a basic example of what such a Markov chain would look if we wanted to model the weather in the evening given the weather in the morning: </p>\n",
    "\n",
    "<img src=\"markov.png\">\n",
    "\n",
    "The starting \"state\" is listed on the left, while the column gives the final outcome. If we wanted to know the probability of Evening Sun given that it there was Morning rain, we would get 0.25 - a 25% chance of that outcome. Note that each row of this matrix is normalized, a statement that if you start in a state, there is a 100% chance that something happens. Nothing tricky here.\n",
    "\n",
    "\n",
    "We can use this concept to build "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "characters = list('abcdefghijklmnopqrstuvwxyz ')\n",
    "cipher     = np.random.permutation(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# take jumbled code to english\n",
    "correct_map = {code:   actual for code, actual in zip(cipher, characters)}\n",
    "# take english to jumbled code\n",
    "jumbler     = {actual: code for code, actual in correct_map.items()}\n",
    "# indices of correct english\n",
    "alpha_lookup = {letter: i for i, letter in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get english transition matrix\n",
    "# TODO: make a function that calculations likelihood of observations\n",
    "# TODO: get jumbled matrix transition matrix\n",
    "# use metropolis hastings to propose char swaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_chapter(doc):\n",
    "    intermediate = re.sub(r'[^a-z]', ' ', doc)  \n",
    "    return re.sub(r\"\\s\\s+\", \" \", intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['chapter', '1', 'loomings', ..., 'in', 'the', 'air'], dtype='<U14')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapter = np.loadtxt('./moby_dick/chapter_1.txt', dtype=str)\n",
    "chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_chapter = clean_chapter(\" \".join(chapter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cooccurrence_matrix(corpus, smooth_factor=0.01):\n",
    "    \"\"\"\n",
    "    Matrix of counts\n",
    "    \n",
    "    first index is starting char, \n",
    "    second is following char\n",
    "    \"\"\"\n",
    "    \n",
    "    counts = np.zeros(shape=(len(characters), len(characters)))\n",
    "    last = None\n",
    "    for index, char in enumerate(corpus):\n",
    "        if index == 0:\n",
    "            last = alpha_lookup[char]\n",
    "            continue\n",
    "            \n",
    "        current = alpha_lookup[char]\n",
    "        counts[last, current] += 1\n",
    "        last = current\n",
    "    \n",
    "    return counts + smooth_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transition_matrix(corpus, smooth_factor=0.01):\n",
    "    mx = make_cooccurrence_matrix(corpus, smooth_factor)\n",
    "    total_ocs = np.sum(mx, axis=1).reshape(-1, 1)\n",
    "    return mx / total_ocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = make_transition_matrix(cleaned_chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.028897233350496692, 0.028894472361809045)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these should be about the same (up to a smoothing factor)\n",
    "tm[0, 1], cleaned_chapter.count('ab') / cleaned_chapter.count('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logprob of observation is np.sum(np.log(make_transition_matrix(english) * make_cooccurrence_matrix(observation)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine learning sandbox",
   "language": "python",
   "name": "data-science-environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
